import streamlit as st
import ollama
import os  

# ã‚¿ã‚¤ãƒˆãƒ«è¨­å®š
st.title("ğŸ‘¨â€ğŸ« æ‰‹å¡šå…ˆç”ŸChat")

# --- å¤‰æ›´ç‚¹ã“ã“ã‹ã‚‰ ---
# ç’°å¢ƒå¤‰æ•° OLLAMA_HOST ãŒã‚ã‚Œã°ãã‚Œã‚’ä½¿ã„ã€ãªã‘ã‚Œã°ãƒ­ãƒ¼ã‚«ãƒ«ã‚’ä½¿ã†
ollama_host = os.getenv("OLLAMA_HOST", None)

if ollama_host:
    # ã‚¯ãƒ©ã‚¦ãƒ‰ã‹ã‚‰è‡ªå®…ã®PCã«æ¥ç¶šã™ã‚‹å ´åˆ
    client = ollama.Client(host=ollama_host)
else:
    # é€šå¸¸ã®ãƒ­ãƒ¼ã‚«ãƒ«æ¥ç¶š
    client = ollama
# --- å¤‰æ›´ç‚¹ã“ã“ã¾ã§ ---

if "messages" not in st.session_state:
    st.session_state["messages"] = []

for message in st.session_state["messages"]:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›..."):
    st.session_state["messages"].append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        response_container = st.empty()
        full_response = ""
        
        # client.chat ã‚’ä½¿ã†ã‚ˆã†ã«å¤‰æ›´
        stream = client.chat(
            model="gemma3", 
            messages=st.session_state["messages"],
            stream=True,
        )
        
        for chunk in stream:
            content = chunk['message']['content']
            full_response += content
            response_container.markdown(full_response + "â–Œ")
            
        response_container.markdown(full_response)
    
    st.session_state["messages"].append({"role": "assistant", "content": full_response})
