import streamlit as st
import ollama
import os

# ã‚¿ã‚¤ãƒˆãƒ«è¨­å®š
st.title("ğŸ‘¨â€ğŸ« æ‰‹å¡šå…ˆç”ŸChat")

# --- è¨­å®šå¤‰æ›´ã‚¨ãƒªã‚¢ ---
# ç’°å¢ƒå¤‰æ•° OLLAMA_HOST ãŒã‚ã‚Œã°ãã‚Œã‚’ä½¿ã„ã€ãªã‘ã‚Œã°ãƒ­ãƒ¼ã‚«ãƒ«ã‚’ä½¿ã†
ollama_host = os.getenv("OLLAMA_HOST", None)

if ollama_host:
    # ã‚¯ãƒ©ã‚¦ãƒ‰ç­‰ã‹ã‚‰æŒ‡å®šã•ã‚ŒãŸæ¥ç¶šå…ˆãŒã‚ã‚‹å ´åˆ
    client = ollama.Client(host=ollama_host)
else:
    # é€šå¸¸ã®ãƒ­ãƒ¼ã‚«ãƒ«æ¥ç¶šï¼ˆè‡ªåˆ†ã®PCå†…ï¼‰
    client = ollama
# --------------------

# å±¥æ­´ã®ä¿å­˜å ´æ‰€ã‚’ä½œã‚‹
if "messages" not in st.session_state:
    st.session_state["messages"] = []

# éå»ã®ä¼šè©±ã‚’è¡¨ç¤º
for message in st.session_state["messages"]:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ãƒãƒ£ãƒƒãƒˆå…¥åŠ›æ™‚ã®å‡¦ç†
if prompt := st.chat_input("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›..."):
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’è¡¨ç¤º
    st.session_state["messages"].append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # AIã®å¿œç­”ã‚’è¡¨ç¤º
    with st.chat_message("assistant"):
        response_container = st.empty()
        full_response = ""
        
        # ã“ã“ã§æ¥ç¶šå…ˆã‚’åˆ‡ã‚Šæ›¿ãˆãŸ client ã‚’ä½¿ã†
        stream = client.chat(
            model="gemma3", 
            messages=st.session_state["messages"],
            stream=True,
        )
        
        for chunk in stream:
            content = chunk['message']['content']
            full_response += content
            response_container.markdown(full_response + "â–Œ")
            
        response_container.markdown(full_response)
    
    # å±¥æ­´ã«è¿½åŠ 
    st.session_state["messages"].append({"role": "assistant", "content": full_response})
